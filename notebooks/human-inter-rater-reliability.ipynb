{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0c9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac218c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "may = pd.read_csv('../pipeline/src/data/may_base_scenarios_manual_validation.csv')\n",
    "kela = pd.read_csv('../pipeline/src/data/base_scenarios_manual_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2cff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different cells (excluding the first column): 34\n",
      "Total number of cells (excluding the first column): 448\n"
     ]
    }
   ],
   "source": [
    "diff_count = (may.iloc[:, 1:] != kela.iloc[:, 1:]).sum().sum()\n",
    "print(\"Number of different cells (excluding the first column):\", diff_count)\n",
    "print(\"Total number of cells (excluding the first column):\", may.iloc[:, 1:].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc8462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.7990713381173491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Flatten the ratings (excluding the 'id' column)\n",
    "may_ratings = may.iloc[:, 1:].values.flatten()\n",
    "kela_ratings = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "kappa = cohen_kappa_score(may_ratings, kela_ratings)\n",
    "print(\"Cohen's kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d74220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's correlation coefficient: 0.8018203347496713\n",
      "p-value: 8.714720238929512e-102\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Flatten the ratings (excluding the 'id' column)\n",
    "may_flat = may.iloc[:, 1:].values.flatten()\n",
    "kela_flat = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "corr, p_value = pearsonr(may_flat, kela_flat)\n",
    "print(\"Pearson's correlation coefficient:\", corr)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fd1414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi coefficient: 0.8018203347496715\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the ratings (excluding the 'id' column)\n",
    "may_bin = may.iloc[:, 1:].values.flatten()\n",
    "kela_bin = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "# Build 2x2 contingency table\n",
    "table = np.zeros((2, 2), dtype=int)\n",
    "for a, b in zip(may_bin, kela_bin):\n",
    "    table[a, b] += 1\n",
    "\n",
    "# Calculate phi coefficient\n",
    "chi2, _, _, _ = chi2_contingency(table, correction=False)\n",
    "n = table.sum()\n",
    "phi = np.sqrt(chi2 / n)\n",
    "print(\"Phi coefficient:\", phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf48a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen = pd.read_csv('../pipeline/src/data/qwen_as_judge_binary_2025-08-23-12-44-27.csv')\n",
    "gemini = pd.read_csv('../pipeline/src/data/gemini_as_judge_binary_2025-08-23-12-59-15.csv')\n",
    "mistral = pd.read_csv('../pipeline/src/data/magistral_as_judge_binary_2025-08-23-13-07-35.csv')\n",
    "kela = pd.read_csv('../pipeline/src/data/base_scenarios_manual_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ffdaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.6667388011252975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Flatten the ratings (excluding the 'id' column)\n",
    "qwen_ratings = qwen.iloc[:, 1:].values.flatten()\n",
    "kela_ratings = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "kappa = cohen_kappa_score(qwen_ratings, kela_ratings)\n",
    "print(\"Cohen's kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca9e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.7490943755958055\n"
     ]
    }
   ],
   "source": [
    "# Flatten the ratings (excluding the 'id' column)\n",
    "gemini_ratings = gemini.iloc[:, 1:].values.flatten()\n",
    "kela_ratings = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "kappa = cohen_kappa_score(gemini_ratings, kela_ratings)\n",
    "print(\"Cohen's kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a21402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.2831016825164594\n"
     ]
    }
   ],
   "source": [
    "# Flatten the ratings (excluding the 'id' column)\n",
    "mistral_ratings = mistral.iloc[:, 1:].values.flatten()\n",
    "kela_ratings = kela.iloc[:, 1:].values.flatten()\n",
    "\n",
    "kappa = cohen_kappa_score(mistral_ratings, kela_ratings)\n",
    "print(\"Cohen's kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7327ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_column_name(col_name):\n",
    "    \"\"\"Parse model-criteria column names.\"\"\"\n",
    "    parts = col_name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        model = parts[0]\n",
    "        criteria = '_'.join(parts[1:])  # Handle criteria_1, criteria_2, etc.\n",
    "        return model, criteria\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9911305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     criteria  avg_agreement  min_agreement  max_agreement  std_agreement\n",
      "0  criteria_1          70.31          50.00           87.5          15.63\n",
      "1  criteria_2          95.31          87.50          100.0           5.98\n",
      "2  criteria_3          90.62          68.75          100.0          14.88\n",
      "3  criteria_4          84.38          75.00          100.0          10.83\n",
      "4  criteria_5          98.44          93.75          100.0           3.12\n",
      "5  criteria_6          81.25          62.50           87.5          12.50\n",
      "6  criteria_7          93.75          87.50          100.0           7.22\n",
      "     criteria  avg_agreement  min_agreement  max_agreement  std_agreement\n",
      "0  criteria_1          93.75          81.25         100.00           8.84\n",
      "1  criteria_2          95.31          87.50         100.00           5.98\n",
      "2  criteria_3          90.62          68.75         100.00          14.88\n",
      "3  criteria_4          87.50          68.75          93.75          12.50\n",
      "4  criteria_5          98.44          93.75         100.00           3.12\n",
      "5  criteria_6          73.44          50.00          87.50          16.44\n",
      "6  criteria_7          87.50          81.25          93.75           5.10\n",
      "     criteria  avg_agreement  min_agreement  max_agreement  std_agreement\n",
      "0  criteria_1          45.31          12.50           62.5          22.46\n",
      "1  criteria_2          92.19          87.50          100.0           5.98\n",
      "2  criteria_3          90.62          68.75          100.0          14.88\n",
      "3  criteria_4          81.25          68.75          100.0          13.50\n",
      "4  criteria_5          71.88          56.25           87.5          14.88\n",
      "5  criteria_6          62.50          50.00           75.0          14.43\n",
      "6  criteria_7          92.19          87.50          100.0           5.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Percent Agreement calculation\n",
    "def calculate_percent_agreement(df1, df2):\n",
    "    \"\"\"Calculate percent agreement for each model-criteria combination.\"\"\"\n",
    "    columns_to_check = [col for col in df1.columns if col != 'id']\n",
    "    results = []\n",
    "    \n",
    "    for col in columns_to_check:\n",
    "        percent_agreement = np.mean(df1[col] == df2[col]) * 100\n",
    "        \n",
    "        # Parse column name\n",
    "        model, criteria = parse_column_name(col)\n",
    "        \n",
    "        results.append({\n",
    "            #'column': col,\n",
    "            'model': model,\n",
    "            'criteria': criteria,\n",
    "            'percent_agreement': round(percent_agreement, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def agreement_summary_by_criteria(df1, df2):\n",
    "    \"\"\"Calculate average percent agreement by criteria across models.\"\"\"\n",
    "    agreement_df = calculate_percent_agreement(df1,df2)\n",
    "    \n",
    "    summary = agreement_df.groupby('criteria')['percent_agreement'].agg([\n",
    "        'mean', 'min', 'max', 'std'\n",
    "    ]).round(2)\n",
    "    \n",
    "    summary.columns = ['avg_agreement', 'min_agreement', 'max_agreement', 'std_agreement']\n",
    "    return summary.reset_index()\n",
    "\n",
    "agreement_df = agreement_summary_by_criteria(qwen, kela)\n",
    "print(agreement_df)\n",
    "agreement_df = agreement_summary_by_criteria(gemini, kela)\n",
    "print(agreement_df)\n",
    "agreement_df = agreement_summary_by_criteria(mistral, kela)\n",
    "print(agreement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d30a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-crises-llm-evaluation-6oGcUsEi-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
